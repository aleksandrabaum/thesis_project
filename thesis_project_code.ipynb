{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import requests, re\n",
    "from bs4 import BeautifulSoup\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import combinations\n",
    "from scipy.stats import fisher_exact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the list of gene names from ACMG list, drawn from NCBI website\n",
    "\n",
    "acmg_url = 'https://www.ncbi.nlm.nih.gov/clinvar/docs/acmg/'\n",
    "\n",
    "response = requests.get(acmg_url)\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "results = soup.find(id=\"maincontent\")\n",
    "\n",
    "column_index = 2\n",
    "acmg_genes = []\n",
    "\n",
    "for cell in results.find_all('td'):\n",
    "    if cell.find('a') and 'genes' in cell.find('a').get('href', ''):\n",
    "        gene = cell.text.strip()\n",
    "        # Cleaning the gene name by removing any content in parentheses\n",
    "        gene = re.sub(r'\\([^)]*\\)', '', gene).strip()\n",
    "        acmg_genes.append(gene)\n",
    "\n",
    "acmg_set = set(acmg_genes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_endpoint(server, request, content_type):\n",
    "\n",
    "    r = requests.get(server+request, headers={ \"Accept\" : content_type})\n",
    "\n",
    "    if not r.ok:\n",
    "        r.raise_for_status()\n",
    "        sys.exit()\n",
    "\n",
    "    if content_type == 'application/json':\n",
    "        return r.json()\n",
    "    else:\n",
    "        return r.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for getting the gene positions from Ensembl database\n",
    "\n",
    "def get_gene(gene: str, grch: str='grch37'):\n",
    "\n",
    "    # Getting the Ensembl server and extension\n",
    "    if grch == 'grch37':\n",
    "        ens_serv: str = f'http://{grch}.rest.ensembl.org/'\n",
    "    elif grch == 'grch38':\n",
    "        ens_serv: str = f'http://rest.ensembl.org/'\n",
    "    else:\n",
    "        raise Exception('Please provide a correct grch assembly! (grch37/grch38 are supported)')\n",
    "    \n",
    "    # Connecting to server and getting data\n",
    "    ens_ext: str = f'lookup/symbol/homo_sapiens/{gene}'\n",
    "    con: str = 'application/json'\n",
    "\n",
    "    return fetch_endpoint(ens_serv, ens_ext, con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing ACMG-listed gene positions into a new file\n",
    "\n",
    "output_file = 'regions.bed'\n",
    "\n",
    "os.system(f'touch {output_file}')\n",
    "with open(f'{output_file}', 'a') as f:\n",
    "    for idx, gene in reversed(list(enumerate(acmg_set))):\n",
    "        gene_json = get_gene(gene)\n",
    "        chromosome = gene_json['seq_region_name']\n",
    "        start = gene_json['start'] - 10000  # Ensuring comprehensive coverage of variant positions of the genes\n",
    "        end = gene_json['end'] + 10000   # Ensuring comprehensive coverage of variant positions of the genes\n",
    "        location = f'{chromosome}\\t{start}\\t{end}'\n",
    "        if idx > 0:\n",
    "            f.write(location)\n",
    "            f.write('\\n')\n",
    "        else:\n",
    "            f.write(location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting ACMG-listed gene positions from the gnomAD database\n",
    "\n",
    "os.system(f'bcftools view --regions-file regions.bed -Oz gnomad.genomes.r2.1.1.sites.vcf.bgz > gnomad.genomes.regions.r2.1.1.sites.vcf.gz')\n",
    "os.system(f'bcftools index gnomad.genomes.regions.r2.1.1.sites.vcf.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing the format of the reduced database - to exclude the extensive information\n",
    "\n",
    "os.system(f'bcftools query -f \"%CHROM\\t%POS\\t%ID\\t%REF\\t%ALT\\t%QUAL\\t%FILTER\\t%INFO/AF;%INFO/vep\\n\" -o extracted_gnomad.genomes.regions.r2.1.1.sites.vcf.gz gnomad.genomes.regions.r2.1.1.sites.vcf.gz')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fields for annotation\n",
    "\n",
    "fields = \"AF,MAX_AF,AFR_AF,AMR_AF,EAS_AF,EUR_AF,SAS_AF,Existing_variation,Allele,Consequence,Gene,NMD,SYMBOL,SYMBOL_SOURCE,IMPACT,ClinVar,ClinVar_CLNREVSTAT,ClinVar_AF_EXAC,ClinVar_CLNDISDB,ClinVar_CLNDISDBINCL,ClinVar_CLNSIG,ClinVar_CLNSIGCONF,ClinVar_CLNSIGINCL,ClinVar_CLNVC,ClinVar_GENEINFO,ClinVar_RS,gnomADg,gnomADg_AN,gnomADg_AC,gnomADg_AF,PUBMED,SIFT,PolyPhen,BIOTYPE,Feature_type,Feature,CLIN_SIG\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VEP annotation\n",
    "\n",
    "os.system(f' vep --offline -i extracted_gnomad.genomes.regions.r2.1.1.sites.vcf.gz --assembly GRCh37 --vcf --af --max_af --af_1kg \\\n",
    "--fields {fields} --per_gene -o out_extracted_gnomad.vcf --force_overwrite --fork 5 --plugin NMD \\\n",
    "--custom /data/clinvar.vcf.gz,ClinVar,vcf,exact,0,CLNREVSTAT,AF_EXAC,CLNDISDB,CLNDISDBINCL,CLNSIG,CLNSIGCONF,CLNSIGINCL,CLNVC,GENEINFO,RS \\\n",
    "--custom file=gnomad.genomes.regions.r2.1.1.sites.vcf.gz,short_name=gnomADg,format=vcf,type=exact,coords=0,fields=AN%AC%AF%AF_afr%AF_amr%AF_asj%AF_eas%AF_fin%AF_nfe%AF_oth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for reading VCF files\n",
    "\n",
    "def read_genotyped_file(path_to_file: str, separators=[\"\\t\", \",\"], possible_number_of_cols = [4,5],\n",
    "                        possible_header_starts = [\"RSID\", \"rsid\", \"#CHROM\", \"rsID\"]) -> pd.DataFrame:\n",
    "\n",
    "    with open(path_to_file, 'r') as f:\n",
    "        header = None\n",
    "        for line in f:\n",
    "            if line.startswith('#'):\n",
    "                header = line\n",
    "            else:\n",
    "                if header is None:\n",
    "                    header = line\n",
    "                break # Stop when there are no more\n",
    "\n",
    "    is_header = any([(header_start in header) for header_start in possible_header_starts])\n",
    "\n",
    "    if is_header:\n",
    "        for separator in separators:\n",
    "            header_names = header[1:]\n",
    "            header_names = header_names.strip().split(separator)\n",
    "            if len(header_names)==1:\n",
    "                continue\n",
    "\n",
    "            data = pd.read_csv(path_to_file, sep=separator, comment='#', names=header_names)\n",
    "\n",
    "            if data.shape[1] in possible_number_of_cols:\n",
    "                break\n",
    "\n",
    "    else:\n",
    "        for separator in separators:\n",
    "            data = pd.read_csv(path_to_file, sep=separator, comment='#')\n",
    "\n",
    "            if data.shape[1] in possible_number_of_cols:\n",
    "                break\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering out variants with AF above 0.05\n",
    "\n",
    "df1 = read_genotyped_file('out_extracted_gnomad.vcf')\n",
    "df_5 = df1[\n",
    "    (df1['INFO'].apply(lambda x: float(x.split(';')[0])) <= 0.05) |\n",
    "    (df1['INFO'].apply(lambda x: float(x.split(';')[0])).isna())\n",
    "]\n",
    "df_5.to_csv('below5_extracted_gnomad.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the variant database from ClinVar\n",
    "df_clinvar = pd.read_csv(f'clinvar/variant_summary.txt', sep='\\t')\n",
    "\n",
    "# Filtering out variants with GRCh38 assembly from the ClinVar database and creating a position ID (POS_ID) column\n",
    "df_clinvar = df_clinvar[df_clinvar['Assembly'] != 'GRCh38']\n",
    "df_clinvar['POS_ID'] = df_clinvar.apply(lambda row: f\"{row['Chromosome']}-{row['PositionVCF']}-{row['ReferenceAlleleVCF']}-{row['AlternateAlleleVCF']}\", axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns in the new format\n",
    "column_names = ['CHROM','POS','ID','REF','ALT','QUAL','FILTER','INFO']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gnom = pd.read_csv(f'below5_extracted_gnomad.csv', sep=',', names=column_names)\n",
    "\n",
    "# Creating a position ID (POS_ID) column\n",
    "df_gnom['POS_ID'] = df_gnom.apply(lambda row: f\"{row['CHROM']}-{row['POS']}-{row['REF']}-{row['ALT']}\", axis=1)\n",
    "\n",
    "# Merging gnomAD and ClinVar databases\n",
    "merged_df = pd.merge(df_gnom, df_clinvar, on='POS_ID', how='left')\n",
    "merged_df.to_csv(f'clinvar_extracted_gnomad.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New columns names including the columns from ClinVar database\n",
    "columns = ['CHROM','POS','ID','REF','ALT','QUAL','FILTER','INFO','POS_ID','AlleleID','Type','Name','GeneID','GeneSymbol','HGNC_ID','ClinicalSignificance','ClinSigSimple','LastEvaluated','RS# (dbSNP)','nsv/esv (dbVar)','RCVaccession','PhenotypeIDS','PhenotypeList','Origin','OriginSimple','Assembly','ChromosomeAccession','Chromosome','Start','Stop','ReferenceAllele','AlternateAllele','Cytogenetic','ReviewStatus','NumberSubmitters','Guidelines','TestedInGTR','OtherIDs','SubmitterCategories','VariationID','PositionVCF','ReferenceAlleleVCF','AlternateAlleleVCF']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering variants with HIGH impact or Pathogenic/Likely pathogenic clinical significance\n",
    "\n",
    "df_clin = pd.read_csv(f'clinvar_extracted_gnomad.csv', sep=',', names=columns)\n",
    "final_clin_df = df_clin[df_clin['INFO'].str.contains('HIGH') | df_clin['ClinicalSignificance'].str.contains('Pathogenic') | df_clin['ClinicalSignificance'].str.contains('Pathogenic/Likely pathogenic') | df_clin['ClinicalSignificance'].str.contains('Likely pathogenic')]\n",
    "final_clin_df.to_csv(f'cv_patho_high.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding RS IDs of the filtered variants to find the matching rows in the gnomAD database\n",
    "\n",
    "df = pd.read_csv('cv_patho_high.csv', sep=',', names=columns)\n",
    "ids = df['ID']   # Finding all IDs\n",
    "ids.to_csv('rs_ids_cv_patho_high.txt', index=False, header=False)\n",
    "\n",
    "with open('rs_ids_cv_patho_high.txt', 'r') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "filtered_lines = [line.strip() for line in lines if '.' not in line]     # Finding only known IDs - so not '.'\n",
    "\n",
    "with open('rs_ids.txt', 'w') as file:\n",
    "    for line in filtered_lines:\n",
    "        file.write(line + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('cv_patho_high.csv', sep=',', names=columns)\n",
    "filtered_df = df[df['ID'] == '.']    # Finding all rows with '.' as ID\n",
    "filtered_values = filtered_df[['CHROM', 'POS']]     # Finding positions of variants in these rows and writing them into a file\n",
    "filtered_values.to_csv('rs_ids_unknown.txt', sep='\\t', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the matching rows in the gnomAD database\n",
    "\n",
    "os.system(f\"bcftools view -i ID=@rs_ids.txt gnomad.genomes.regions.r2.1.1.sites.vcf.gz > gnomad_zip_rows_tomatch.vcf\")   # By RS IDs\n",
    "os.system(f\"bcftools view -R 'rs_ids_unknown.txt' gnomad.genomes.regions.r2.1.1.sites.vcf.gz > gnomad_zip_rows_tomatch_unknown.vcf\")  # By positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gnomad = read_genotyped_file('gnomad_zip_rows_tomatch.vcf')\n",
    "df_gnomad_2 = read_genotyped_file('gnomad_zip_rows_tomatch_dots.vcf')\n",
    "\n",
    "# Merging the rows from both files to later attach previously left out information from INFO column\n",
    "combined_df = pd.concat([df_gnomad, df_gnomad_2], ignore_index=True)\n",
    "\n",
    "# Merging the information from both dataframes\n",
    "df_clin = pd.read_csv('cv_patho_high.csv', sep=',', names=columns)\n",
    "combined_df['POS_ID'] = combined_df.apply(lambda row: f\"{row['CHROM']}-{row['POS']}-{row['REF']}-{row['ALT']}\", axis=1)\n",
    "merged_df = pd.merge(df_clin, combined_df, on='POS_ID', how='left')\n",
    "merged_df.to_excel('cv_patho_high_full_info.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting information from INFO column into separate columns for easy filtering\n",
    "\n",
    "def extract_info(row, chosen_fields):\n",
    "    csq_info = row['INFO_x'].split('CSQ=')[1]\n",
    "    csq_fields = csq_info.split('|')\n",
    "    chosen_fields = [csq_fields[i] if csq_fields[i] else '-' for i in chosen_fields]\n",
    "    return pd.Series(chosen_fields)\n",
    "\n",
    "def process_dataframe(df, chosen_indices, new_column_names):\n",
    "    new_columns = df.apply(extract_info, args=(chosen_indices,), axis=1)\n",
    "    new_columns.columns = new_column_names\n",
    "\n",
    "    # Concatenating the new columns with the original df\n",
    "    df = pd.concat([df.loc[:, :'INFO_x'], new_columns, df.loc[:, 'INFO_x':]], axis=1)\n",
    "    df = df.loc[:, ~df.columns.duplicated()]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('cv_patho_high_full_info.xlsx')\n",
    "df = df[df['Assembly'] != 'GRCh38']\n",
    "\n",
    "# Choosing the names for new columns (names drawn from VEP) and their respective indices in the INFO column\n",
    "chosen_indices = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36]\n",
    "new_column_names = ['AF','MAX_AF','AFR_AF','AMR_AF','EAS_AF','EUR_AF','SAS_AF','Existing_variation','Allele','Consequence','Gene','NMD','SYMBOL','SYMBOL_SOURCE','IMPACT','ClinVar','ClinVar_CLNREVSTAT','ClinVar_AF_EXAC','ClinVar_CLNDISDB','ClinVar_CLNDISDBINCL','ClinVar_CLNSIG','ClinVar_CLNSIGCONF','ClinVar_CLNSIGINCL','ClinVar_CLNVC','ClinVar_GENEINFO','ClinVar_RS','gnomADg','gnomADg_AN','gnomADg_AC','gnomADg_AF','PUBMED','SIFT','PolyPhen','BIOTYPE','Feature_type','Feature','CLIN_SIG']\n",
    "\n",
    "# Processing the dataframe to extract the new columns\n",
    "df_all = process_dataframe(df, chosen_indices, new_column_names)\n",
    "\n",
    "# Filtering out rows with 'NMD_escaping_variant' in NMD column\n",
    "filtered_df = df_all[df_all['NMD'] != 'NMD_escaping_variant']\n",
    "\n",
    "filtered_df.to_excel('final_table.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('final_table.xlsx')\n",
    "\n",
    "# Finding the AC and AN values for a population\n",
    "\n",
    "def extract_population_freq(info_string, population):\n",
    "    pattern = f\"AC_{population}=([0-9]+);AN_{population}=([0-9]+)\"\n",
    "    match = re.search(pattern, info_string)\n",
    "    if match:\n",
    "        ac, an = match.groups()\n",
    "        return float(ac), float(an)\n",
    "    else:\n",
    "        return None, None\n",
    "    \n",
    "populations = ['amr', 'asj', 'afr', 'eas', 'fin', 'nfe_nwe', 'nfe_seu', 'nfe_onf', 'nfe_est'] \n",
    "for population in populations:\n",
    "    ac_values = []\n",
    "    an_values = []\n",
    "    for index, row in df.iterrows():\n",
    "        ac, an = extract_population_freq(row['INFO_y'], population) \n",
    "        ac_values.append(ac)\n",
    "        an_values.append(an)\n",
    "    # Adding new columns in the dataframe - for AC and AN values per population\n",
    "    df[f'AC_{population}'] = ac_values\n",
    "    df[f'AN_{population}'] = an_values\n",
    "    \n",
    "for population in populations:\n",
    "    df[f'Frequency_{population}'] = df[f'AC_{population}'] / df[f'AN_{population}']   # Adding another column for the AC/AN ratio per population\n",
    "df.to_excel('populations_final.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistical analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('populations_final.xlsx')\n",
    "\n",
    "# Removing duplicate rows based on the POS_ID column - if they exist\n",
    "df_cleaned = df.drop_duplicates(subset=['POS_ID'])\n",
    "\n",
    "df_cleaned.to_excel('cleaned_file_posid.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('cleaned_file_posid.xlsx')\n",
    "\n",
    "# Filtering rows where number of submitters is 2 or more, or is NaN\n",
    "df_filtered = df[(df['NumberSubmitters'] >= 2) | (df['NumberSubmitters'].isna())]\n",
    "\n",
    "# Filtering out variants with conflicting interpretations of pathogenicity\n",
    "df_filtered_conflics = df_filtered[df_filtered['ClinicalSignificance'] != 'Conflicting interpretations of pathogenicity']\n",
    "\n",
    "df_filtered_conflics.to_excel('filtered_more_submits.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CV_P+HIGH_VEP experiment\n",
    "\n",
    "df = pd.read_excel('filtered_more_submits.xlsx')\n",
    "\n",
    "lst = ['Pathogenic','Pathogenic/Likely pathogenic','Likely pathogenic','Pathogenic; drug response','Likely pathogenic; drug response']\n",
    "\n",
    "# Filtering rows where clinical significance is included in the lst list or is NaN\n",
    "df_filtered_ag = df_filtered.loc[(df_filtered['ClinicalSignificance'].isin(lst)) | (df_filtered['ClinicalSignificance'].isna()),]\n",
    "\n",
    "df_filtered_ag.to_excel('cv_p_high_vep.xlsx' , index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CV_P experiment\n",
    "\n",
    "df = pd.read_excel('filtered_more_submits.xlsx')\n",
    "\n",
    "lst = ['Pathogenic','Pathogenic/Likely pathogenic','Likely pathogenic','Pathogenic; drug response','Likely pathogenic; drug response']\n",
    "\n",
    "# Filtering rows where clinical significance is included in the lst list\n",
    "df_filtered_ag = df_filtered.loc[(df_filtered['ClinicalSignificance'].isin(lst)),]\n",
    "\n",
    "df_filtered_ag.to_excel('cv_p.xlsx' , index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually choosing one or the other experiment\n",
    "\n",
    "df = pd.read_excel('cv_p_high_vep.xlsx')  # CV_P+HIGH_VEP experiment\n",
    "# df = pd.read_excel('cv_p.xlsx')  # CV_P experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "an_columns = ['AN_amr', 'AN_asj', 'AN_afr', 'AN_eas', 'AN_fin', 'AN_nfe_nwe', 'AN_nfe_seu', 'AN_nfe_est', 'AN_nfe_onf'] \n",
    "ac_columns = ['AC_amr', 'AC_asj', 'AC_afr', 'AC_eas', 'AC_fin', 'AC_nfe_nwe', 'AC_nfe_seu', 'AC_nfe_est', 'AC_nfe_onf']  \n",
    "\n",
    "# Initializing dictionaries to store median and sum results\n",
    "median_results_an = {}\n",
    "sums_ac = {}\n",
    "ratios_median = {}\n",
    "\n",
    "for column in an_columns:\n",
    "    # Calculating the median of the current AN column within each group\n",
    "    median_results_an[column] = df.groupby('SYMBOL')[column].median().reset_index()\n",
    "    \n",
    "for column in ac_columns:\n",
    "    # Calculating the sum of the current AC column within each group\n",
    "    sums_ac[column] = df.groupby('SYMBOL')[column].sum().reset_index()\n",
    "\n",
    "results_median = []\n",
    "\n",
    "for key in sums_ac.keys():\n",
    "    ac_df = sums_ac[key]\n",
    "    an_df = median_results_an[key.replace(\"AC\", \"AN\")]\n",
    "    \n",
    "    # Merging the DataFrames on 'SYMBOL' column\n",
    "    merged_df = pd.merge(ac_df, an_df, on='SYMBOL')\n",
    "    \n",
    "    # Dividing AC sums by AN medians\n",
    "    merged_df[f'AC/AN_ratio_{key}'] = merged_df[key] / merged_df[key.replace(\"AC\", \"AN\")]\n",
    "    \n",
    "    results_median.append(merged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating dictionary with population names as keys and their respective dataframes as items\n",
    "\n",
    "df_dict_median = {}\n",
    "\n",
    "for df in results_median:\n",
    "    for column in df.columns:\n",
    "        if column.startswith('AN_'):\n",
    "            column = column.lstrip('AN_')\n",
    "            df_dict_median[column] = df\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full populations names\n",
    "full_names_pop = {'afr':'African','amr':'Latino','asj':'Ashkenazi Jews', 'eas':'East Asian','fin':'Finnish','nfe_nwe':'North-Western European','nfe_seu':'Southern European','nfe_onf':'Other Non-Finnish European','nfe_est':'Estonian'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing data for Fisher's Exact Test\n",
    "\n",
    "population_info = {}\n",
    "\n",
    "for population, df in df_dict_median.items():\n",
    "    filtered_df = df[df['SYMBOL'].isin(acmg_genes)]\n",
    "\n",
    "    population_df = filtered_df[['SYMBOL', f'AC_{population}', f'AN_{population}']]\n",
    "\n",
    "    # Calculating difference between the median of AN values per gene the sum of AC values\n",
    "    population_df[f'AN-AC_{population}'] = filtered_df[f'AN_{population}'] - filtered_df[f'AC_{population}']\n",
    "    \n",
    "    # Converting the dataframe to a list of dictionaries\n",
    "    population_list = population_df.to_dict(orient='records')\n",
    "    \n",
    "    population_info[population] = population_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performing Fisher's Exact Test for each gene\n",
    "\n",
    "fisher_results = {}\n",
    "\n",
    "# Iterating through each gene\n",
    "for symbol in acmg_genes:\n",
    "    if symbol not in [data_dict['SYMBOL'] for data_list in population_info.values() for data_dict in data_list]:\n",
    "        continue  # Skip the symbol if it has no variants\n",
    "\n",
    "    symbol_results = {}\n",
    "    \n",
    "    # Generating all pairs of populations\n",
    "    population_pairs = combinations(population_info.keys(), 2)\n",
    "    \n",
    "    # Iterating through each pair of populations\n",
    "    for population_a, population_b in population_pairs:\n",
    "        data_a = population_info[population_a]\n",
    "        data_b = population_info[population_b]\n",
    "        \n",
    "        # Initializing contingency table\n",
    "        contingency_table = [[], []]\n",
    "        \n",
    "        # Filling contingency table with AC and AN-AC values for the current symbol\n",
    "        for data_dict_a, data_dict_b in zip(data_a, data_b):\n",
    "            if data_dict_a['SYMBOL'] == symbol and data_dict_b['SYMBOL'] == symbol:\n",
    "                contingency_table[0].append(data_dict_a[f'AC_{population_a}'])\n",
    "                contingency_table[1].append(data_dict_b[f'AC_{population_b}'])\n",
    "                contingency_table[0].append(data_dict_a[f'AN-AC_{population_a}'])\n",
    "                contingency_table[1].append(data_dict_b[f'AN-AC_{population_b}'])\n",
    "        \n",
    "        # Performing Fisher's exact test\n",
    "        odds_ratio, p_value = fisher_exact(contingency_table)\n",
    "        symbol_results[(population_a, population_b)] = {'odds_ratio': odds_ratio, 'p_value': p_value}\n",
    "    \n",
    "    # Storing Fisher's exact test results for the current symbol\n",
    "    fisher_results[symbol] = symbol_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating dictionary with phenotypes as keys and lists of corresponding genes as items\n",
    "\n",
    "groups_dict = {}\n",
    "\n",
    "with open('genes phenotypes groups.txt', 'r') as file:    # The .txt file based on the table from Miller et al. (2023)\n",
    "    current_group = None\n",
    "    for line in file:\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            # If the line is empty, it indicates a new group\n",
    "            current_group = None\n",
    "        else:\n",
    "            # If the line is not empty\n",
    "            if current_group is None:\n",
    "                # If current_group is None, it indicates a new group\n",
    "                current_group = line\n",
    "                # Initializing a list for the current group\n",
    "                groups_dict[current_group] = []\n",
    "            else:\n",
    "                # If current_group is not None, appending the symbol to the list of the current group\n",
    "                groups_dict[current_group].append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing the dictionary with genes grouped by phenotype for Fisher's Exact Test\n",
    "\n",
    "results_grouped_dict = {}\n",
    "\n",
    "for population, df in df_dict_median.items():\n",
    "    ac_sums = {}\n",
    "    ac_minus_an_median = {}\n",
    "    \n",
    "    for group, symbols in groups_dict.items():\n",
    "        # Filtering the dataframe to include only symbols in the current group\n",
    "        group_df = df[df['SYMBOL'].isin(symbols)]\n",
    "        \n",
    "        # Calculating the sum of AC values for the current group\n",
    "        ac_sum = group_df[f'AC_{population}'].sum()\n",
    "        ac_sums[group] = ac_sum\n",
    "        \n",
    "        # Calculating difference between the median of AN values per gene the sum of AC values\n",
    "        ac_minus_an_median[group] = group_df[f'AN_{population}'].median() - group_df[f'AC_{population}'].sum()\n",
    "    \n",
    "    results_grouped_dict[population] = {'AC_sums': ac_sums, f'AN-AC_{population}': ac_minus_an_median}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performing Fisher's Exact Test for each phenotype (group)\n",
    "\n",
    "fisher_results_grouped = {}\n",
    "\n",
    "for group_name in list(results_grouped_dict[next(iter(results_grouped_dict))]['AC_sums'].keys()):\n",
    "    fisher_results_grouped[group_name] = {}\n",
    "    \n",
    "    # Iterating through each pair of populations\n",
    "    for population_pair in combinations(results_grouped_dict.keys(), 2):\n",
    "        population_a, population_b = population_pair\n",
    "        \n",
    "        # Population A\n",
    "        ac_sum_a = results_grouped_dict[population_a]['AC_sums'][group_name]\n",
    "        an_minus_ac_a = results_grouped_dict[population_a]['AN-AC_' + population_a][group_name]\n",
    "        \n",
    "        # Population B\n",
    "        ac_sum_b = results_grouped_dict[population_b]['AC_sums'][group_name]\n",
    "        an_minus_ac_b = results_grouped_dict[population_b]['AN-AC_' + population_b][group_name]\n",
    "        \n",
    "        # Constructing the contingency table\n",
    "        contingency_table = [\n",
    "            [ac_sum_a, an_minus_ac_a],\n",
    "            [ac_sum_b, an_minus_ac_b]\n",
    "        ]\n",
    "        \n",
    "        # Performing Fisher's Exact Test\n",
    "        odds_ratio, p_value = fisher_exact(contingency_table)\n",
    "        \n",
    "        fisher_results_grouped[group_name][population_pair] = {'odds_ratio': odds_ratio, 'p_value': p_value}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating plots for each gene\n",
    "\n",
    "for symbol in acmg_genes:\n",
    "    if symbol in fisher_results.keys():\n",
    "        total_ac_an_ratio = 0\n",
    "        for column, median_df in df_dict_median.items():\n",
    "            pop = column\n",
    "            symbol_median_df = median_df[median_df['SYMBOL'] == symbol]\n",
    "            if not symbol_median_df.empty:\n",
    "                total_ac_an_ratio += symbol_median_df[f'AC/AN_ratio_AC_{pop}'].iloc[0]\n",
    "\n",
    "        # Skip plotting if total AC/AN ratio is zero - no variants of the given gene\n",
    "        if total_ac_an_ratio == 0:\n",
    "            continue\n",
    "\n",
    "        plt.figure(figsize=(15, 17))\n",
    "        plt.title(f'Frequency of individuals with a variant present in {symbol} gene', fontsize=20)\n",
    "        plt.xlabel('Populations', fontsize=16)\n",
    "        plt.ylabel('Frequency', fontsize=16)\n",
    "\n",
    "        for i, (column, median_df) in enumerate(df_dict_median.items()):\n",
    "            pop = column\n",
    "            symbol_median_df = median_df[median_df['SYMBOL'] == symbol]\n",
    "            plt.bar(i, symbol_median_df['AC/AN_ratio_AC_' + pop], alpha=0.8, label=f'{column}')\n",
    "\n",
    "        # Adding horizontal lines representing p-values between different population pairs\n",
    "        for i, ((pop1, pop2), p_value_data) in enumerate(fisher_results[symbol].items()):\n",
    "            if p_value_data['p_value'] < 0.05:\n",
    "                p_value = p_value_data['p_value']\n",
    "                x1 = list(df_dict_median.keys()).index(pop1)\n",
    "                x2 = list(df_dict_median.keys()).index(pop2)\n",
    "                y = max(plt.ylim())\n",
    "                plt.plot([x1, x2], [y, y], linewidth=2, color='black')  # Horizontal line\n",
    "                p_value_label = f'{p_value:.4f}' if p_value >= 1e-4 else f'<{0.0001}'  # Writing p-value on the line if it's between 0.05 and 0.0001, if it's smaller, writing '<0.0001'\n",
    "                plt.text((x1 + x2) / 2, y, f'p-value: {p_value_label}', ha='center', va='bottom', fontsize=12)\n",
    "\n",
    "        plt.xticks(range(len(df_dict_median)), [full_names_pop[pop] for pop in df_dict_median.keys()], rotation=-45, fontsize=12)\n",
    "\n",
    "        plt.tight_layout() \n",
    "\n",
    "        # Choosing the directory depending on the experiment\n",
    "        plt.savefig(f'plots_cv_p_high_vep/genes/{symbol}.jpg')   # CV_P+HIGH_VEP experiment\n",
    "        # plt.savefig(f'plots_cv_p/genes/{symbol}.jpg')    # CV_P experiment\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating AC/AN ratios per phenotypes (groups)\n",
    "\n",
    "disease_ratios = {}\n",
    "\n",
    "for disease, symbols in groups_dict.items():\n",
    "    disease_df = pd.DataFrame()\n",
    "    for symbol in symbols:\n",
    "        symbol_data = pd.concat([data[data['SYMBOL'] == symbol] for _, data in df_dict_median.items()])\n",
    "        disease_df = pd.concat([disease_df, symbol_data])\n",
    "    \n",
    "    # Calculating sum of AC values and median of AN values for each population\n",
    "    disease_ratios[disease] = {}\n",
    "    for population, data in df_dict_median.items():\n",
    "        population_subset = disease_df[disease_df['SYMBOL'].isin(symbols)]\n",
    "        ac_sum = population_subset[f'AC_{population}'].sum()\n",
    "        an_median = population_subset[f'AN_{population}'].median()\n",
    "        # Calculating new AC/AN ratio\n",
    "        if an_median != 0:\n",
    "            ratio = ac_sum / an_median\n",
    "        else:\n",
    "            ratio = None  # Handling case where denominator is 0\n",
    "        disease_ratios[disease][population] = ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating plots for each phenotype\n",
    "\n",
    "for disease, ratios_per_population in disease_ratios.items():\n",
    "    plt.figure(figsize=(15, 20))\n",
    "    plt.title(f'Frequency of individuals with a variant present in genes\\nrelated to {disease}', fontsize=20, pad=20)\n",
    "    plt.xlabel('Populations', fontsize=16)\n",
    "    plt.ylabel('Frequency', fontsize=16)\n",
    "\n",
    "    for i, (population, ratio) in enumerate(ratios_per_population.items()):\n",
    "        plt.bar(i, ratio, alpha=0.8, label=f'{population}')\n",
    "    \n",
    "    # Adding horizontal lines representing p-values between different population pairs\n",
    "    if disease in fisher_results_grouped:\n",
    "        for i, ((pop1, pop2), p_value_data) in enumerate(fisher_results_grouped[disease].items()):\n",
    "            if p_value_data['p_value'] < 0.05:\n",
    "                p_value = p_value_data['p_value']\n",
    "                x1 = list(ratios_per_population.keys()).index(pop1)\n",
    "                x2 = list(ratios_per_population.keys()).index(pop2)\n",
    "                y = max(plt.ylim())\n",
    "                plt.plot([x1, x2], [y, y], linewidth=2, color='black')  # Horizontal line\n",
    "                p_value_label = f'{p_value:.4f}' if p_value >= 1e-4 else f'<{0.0001}'  # Writing p-value on the line if it's between 0.05 and 0.0001, if it's smaller, writing '<0.0001'\n",
    "                plt.text((x1 + x2) / 2, y, f'p-value: {p_value_label}', ha='center', va='bottom', fontsize=12)\n",
    "\n",
    "    plt.xticks(range(len(ratios_per_population)), [full_names_pop[pop] for pop in ratios_per_population.keys()], rotation=-45, fontsize=12)\n",
    "\n",
    "    plt.tight_layout() \n",
    "\n",
    "    # Choosing the directory depending on the experiment\n",
    "    plt.savefig(f'plots_cv_p_high_vep/phenotypes/{disease}.jpg')  # CV_P+HIGH_VEP experiment\n",
    "    # plt.savefig(f'plots_cv_p/phenotypes/{disease}.jpg')    # CV_P experiment\n",
    "    plt.close()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
